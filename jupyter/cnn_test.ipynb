{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    'test': DataLoader(test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0}%)]\\t{loss.item():.6f}')\n",
    "            \n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    \n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lp/h9ryjfsj4wx5rsdk3mrqk3nh0000gn/T/ipykernel_17255/2541791753.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0e+00%)]\t2.304632\n",
      "Train Epoch: 1 [2000/60000 (3e+00%)]\t2.244067\n",
      "Train Epoch: 1 [4000/60000 (7e+00%)]\t2.123962\n",
      "Train Epoch: 1 [6000/60000 (1e+01%)]\t1.973491\n",
      "Train Epoch: 1 [8000/60000 (1e+01%)]\t1.954025\n",
      "Train Epoch: 1 [10000/60000 (2e+01%)]\t1.921297\n",
      "Train Epoch: 1 [12000/60000 (2e+01%)]\t1.885449\n",
      "Train Epoch: 1 [14000/60000 (2e+01%)]\t1.793692\n",
      "Train Epoch: 1 [16000/60000 (3e+01%)]\t1.790241\n",
      "Train Epoch: 1 [18000/60000 (3e+01%)]\t1.752920\n",
      "Train Epoch: 1 [20000/60000 (3e+01%)]\t1.799486\n",
      "Train Epoch: 1 [22000/60000 (4e+01%)]\t1.719705\n",
      "Train Epoch: 1 [24000/60000 (4e+01%)]\t1.686608\n",
      "Train Epoch: 1 [26000/60000 (4e+01%)]\t1.680730\n",
      "Train Epoch: 1 [28000/60000 (5e+01%)]\t1.682755\n",
      "Train Epoch: 1 [30000/60000 (5e+01%)]\t1.653360\n",
      "Train Epoch: 1 [32000/60000 (5e+01%)]\t1.636886\n",
      "Train Epoch: 1 [34000/60000 (6e+01%)]\t1.685706\n",
      "Train Epoch: 1 [36000/60000 (6e+01%)]\t1.585325\n",
      "Train Epoch: 1 [38000/60000 (6e+01%)]\t1.700668\n",
      "Train Epoch: 1 [40000/60000 (7e+01%)]\t1.640928\n",
      "Train Epoch: 1 [42000/60000 (7e+01%)]\t1.661457\n",
      "Train Epoch: 1 [44000/60000 (7e+01%)]\t1.643535\n",
      "Train Epoch: 1 [46000/60000 (8e+01%)]\t1.679489\n",
      "Train Epoch: 1 [48000/60000 (8e+01%)]\t1.653174\n",
      "Train Epoch: 1 [50000/60000 (8e+01%)]\t1.616912\n",
      "Train Epoch: 1 [52000/60000 (9e+01%)]\t1.689248\n",
      "Train Epoch: 1 [54000/60000 (9e+01%)]\t1.600785\n",
      "Train Epoch: 1 [56000/60000 (9e+01%)]\t1.605931\n",
      "Train Epoch: 1 [58000/60000 (1e+02%)]\t1.630353\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 9356/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0e+00%)]\t1.638741\n",
      "Train Epoch: 2 [2000/60000 (3e+00%)]\t1.625282\n",
      "Train Epoch: 2 [4000/60000 (7e+00%)]\t1.620683\n",
      "Train Epoch: 2 [6000/60000 (1e+01%)]\t1.555360\n",
      "Train Epoch: 2 [8000/60000 (1e+01%)]\t1.578379\n",
      "Train Epoch: 2 [10000/60000 (2e+01%)]\t1.582486\n",
      "Train Epoch: 2 [12000/60000 (2e+01%)]\t1.595799\n",
      "Train Epoch: 2 [14000/60000 (2e+01%)]\t1.604029\n",
      "Train Epoch: 2 [16000/60000 (3e+01%)]\t1.623626\n",
      "Train Epoch: 2 [18000/60000 (3e+01%)]\t1.592010\n",
      "Train Epoch: 2 [20000/60000 (3e+01%)]\t1.584974\n",
      "Train Epoch: 2 [22000/60000 (4e+01%)]\t1.606050\n",
      "Train Epoch: 2 [24000/60000 (4e+01%)]\t1.600332\n",
      "Train Epoch: 2 [26000/60000 (4e+01%)]\t1.581108\n",
      "Train Epoch: 2 [28000/60000 (5e+01%)]\t1.538004\n",
      "Train Epoch: 2 [30000/60000 (5e+01%)]\t1.603145\n",
      "Train Epoch: 2 [32000/60000 (5e+01%)]\t1.615198\n",
      "Train Epoch: 2 [34000/60000 (6e+01%)]\t1.567586\n",
      "Train Epoch: 2 [36000/60000 (6e+01%)]\t1.611509\n",
      "Train Epoch: 2 [38000/60000 (6e+01%)]\t1.635060\n",
      "Train Epoch: 2 [40000/60000 (7e+01%)]\t1.548543\n",
      "Train Epoch: 2 [42000/60000 (7e+01%)]\t1.557712\n",
      "Train Epoch: 2 [44000/60000 (7e+01%)]\t1.597403\n",
      "Train Epoch: 2 [46000/60000 (8e+01%)]\t1.549028\n",
      "Train Epoch: 2 [48000/60000 (8e+01%)]\t1.569481\n",
      "Train Epoch: 2 [50000/60000 (8e+01%)]\t1.606541\n",
      "Train Epoch: 2 [52000/60000 (9e+01%)]\t1.568188\n",
      "Train Epoch: 2 [54000/60000 (9e+01%)]\t1.601358\n",
      "Train Epoch: 2 [56000/60000 (9e+01%)]\t1.555034\n",
      "Train Epoch: 2 [58000/60000 (1e+02%)]\t1.544868\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 9498/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0e+00%)]\t1.549847\n",
      "Train Epoch: 3 [2000/60000 (3e+00%)]\t1.587412\n",
      "Train Epoch: 3 [4000/60000 (7e+00%)]\t1.553206\n",
      "Train Epoch: 3 [6000/60000 (1e+01%)]\t1.556524\n",
      "Train Epoch: 3 [8000/60000 (1e+01%)]\t1.546903\n",
      "Train Epoch: 3 [10000/60000 (2e+01%)]\t1.548607\n",
      "Train Epoch: 3 [12000/60000 (2e+01%)]\t1.568877\n",
      "Train Epoch: 3 [14000/60000 (2e+01%)]\t1.554142\n",
      "Train Epoch: 3 [16000/60000 (3e+01%)]\t1.588902\n",
      "Train Epoch: 3 [18000/60000 (3e+01%)]\t1.583273\n",
      "Train Epoch: 3 [20000/60000 (3e+01%)]\t1.559286\n",
      "Train Epoch: 3 [22000/60000 (4e+01%)]\t1.552788\n",
      "Train Epoch: 3 [24000/60000 (4e+01%)]\t1.569693\n",
      "Train Epoch: 3 [26000/60000 (4e+01%)]\t1.526434\n",
      "Train Epoch: 3 [28000/60000 (5e+01%)]\t1.547858\n",
      "Train Epoch: 3 [30000/60000 (5e+01%)]\t1.599337\n",
      "Train Epoch: 3 [32000/60000 (5e+01%)]\t1.587459\n",
      "Train Epoch: 3 [34000/60000 (6e+01%)]\t1.534084\n",
      "Train Epoch: 3 [36000/60000 (6e+01%)]\t1.527171\n",
      "Train Epoch: 3 [38000/60000 (6e+01%)]\t1.519000\n",
      "Train Epoch: 3 [40000/60000 (7e+01%)]\t1.540197\n",
      "Train Epoch: 3 [42000/60000 (7e+01%)]\t1.556554\n",
      "Train Epoch: 3 [44000/60000 (7e+01%)]\t1.557175\n",
      "Train Epoch: 3 [46000/60000 (8e+01%)]\t1.549599\n",
      "Train Epoch: 3 [48000/60000 (8e+01%)]\t1.537979\n",
      "Train Epoch: 3 [50000/60000 (8e+01%)]\t1.595023\n",
      "Train Epoch: 3 [52000/60000 (9e+01%)]\t1.562265\n",
      "Train Epoch: 3 [54000/60000 (9e+01%)]\t1.552352\n",
      "Train Epoch: 3 [56000/60000 (9e+01%)]\t1.523827\n",
      "Train Epoch: 3 [58000/60000 (1e+02%)]\t1.534602\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 9552/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0e+00%)]\t1.560482\n",
      "Train Epoch: 4 [2000/60000 (3e+00%)]\t1.615288\n",
      "Train Epoch: 4 [4000/60000 (7e+00%)]\t1.593939\n",
      "Train Epoch: 4 [6000/60000 (1e+01%)]\t1.535015\n",
      "Train Epoch: 4 [8000/60000 (1e+01%)]\t1.603593\n",
      "Train Epoch: 4 [10000/60000 (2e+01%)]\t1.571017\n",
      "Train Epoch: 4 [12000/60000 (2e+01%)]\t1.530594\n",
      "Train Epoch: 4 [14000/60000 (2e+01%)]\t1.530820\n",
      "Train Epoch: 4 [16000/60000 (3e+01%)]\t1.589717\n",
      "Train Epoch: 4 [18000/60000 (3e+01%)]\t1.540330\n",
      "Train Epoch: 4 [20000/60000 (3e+01%)]\t1.551818\n",
      "Train Epoch: 4 [22000/60000 (4e+01%)]\t1.587957\n",
      "Train Epoch: 4 [24000/60000 (4e+01%)]\t1.563601\n",
      "Train Epoch: 4 [26000/60000 (4e+01%)]\t1.536928\n",
      "Train Epoch: 4 [28000/60000 (5e+01%)]\t1.532542\n",
      "Train Epoch: 4 [30000/60000 (5e+01%)]\t1.501182\n",
      "Train Epoch: 4 [32000/60000 (5e+01%)]\t1.555104\n",
      "Train Epoch: 4 [34000/60000 (6e+01%)]\t1.513099\n",
      "Train Epoch: 4 [36000/60000 (6e+01%)]\t1.516402\n",
      "Train Epoch: 4 [38000/60000 (6e+01%)]\t1.520781\n",
      "Train Epoch: 4 [40000/60000 (7e+01%)]\t1.529280\n",
      "Train Epoch: 4 [42000/60000 (7e+01%)]\t1.517104\n",
      "Train Epoch: 4 [44000/60000 (7e+01%)]\t1.580618\n",
      "Train Epoch: 4 [46000/60000 (8e+01%)]\t1.535520\n",
      "Train Epoch: 4 [48000/60000 (8e+01%)]\t1.502921\n",
      "Train Epoch: 4 [50000/60000 (8e+01%)]\t1.517128\n",
      "Train Epoch: 4 [52000/60000 (9e+01%)]\t1.547291\n",
      "Train Epoch: 4 [54000/60000 (9e+01%)]\t1.543260\n",
      "Train Epoch: 4 [56000/60000 (9e+01%)]\t1.496417\n",
      "Train Epoch: 4 [58000/60000 (1e+02%)]\t1.546134\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9604/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0e+00%)]\t1.546855\n",
      "Train Epoch: 5 [2000/60000 (3e+00%)]\t1.513884\n",
      "Train Epoch: 5 [4000/60000 (7e+00%)]\t1.535158\n",
      "Train Epoch: 5 [6000/60000 (1e+01%)]\t1.581163\n",
      "Train Epoch: 5 [8000/60000 (1e+01%)]\t1.560286\n",
      "Train Epoch: 5 [10000/60000 (2e+01%)]\t1.583135\n",
      "Train Epoch: 5 [12000/60000 (2e+01%)]\t1.589440\n",
      "Train Epoch: 5 [14000/60000 (2e+01%)]\t1.559216\n",
      "Train Epoch: 5 [16000/60000 (3e+01%)]\t1.549548\n",
      "Train Epoch: 5 [18000/60000 (3e+01%)]\t1.509013\n",
      "Train Epoch: 5 [20000/60000 (3e+01%)]\t1.531490\n",
      "Train Epoch: 5 [22000/60000 (4e+01%)]\t1.513274\n",
      "Train Epoch: 5 [24000/60000 (4e+01%)]\t1.546677\n",
      "Train Epoch: 5 [26000/60000 (4e+01%)]\t1.514234\n",
      "Train Epoch: 5 [28000/60000 (5e+01%)]\t1.548986\n",
      "Train Epoch: 5 [30000/60000 (5e+01%)]\t1.528124\n",
      "Train Epoch: 5 [32000/60000 (5e+01%)]\t1.543989\n",
      "Train Epoch: 5 [34000/60000 (6e+01%)]\t1.564836\n",
      "Train Epoch: 5 [36000/60000 (6e+01%)]\t1.577070\n",
      "Train Epoch: 5 [38000/60000 (6e+01%)]\t1.581464\n",
      "Train Epoch: 5 [40000/60000 (7e+01%)]\t1.513959\n",
      "Train Epoch: 5 [42000/60000 (7e+01%)]\t1.571007\n",
      "Train Epoch: 5 [44000/60000 (7e+01%)]\t1.565073\n",
      "Train Epoch: 5 [46000/60000 (8e+01%)]\t1.528665\n",
      "Train Epoch: 5 [48000/60000 (8e+01%)]\t1.543123\n",
      "Train Epoch: 5 [50000/60000 (8e+01%)]\t1.566362\n",
      "Train Epoch: 5 [52000/60000 (9e+01%)]\t1.558347\n",
      "Train Epoch: 5 [54000/60000 (9e+01%)]\t1.549898\n",
      "Train Epoch: 5 [56000/60000 (9e+01%)]\t1.532044\n",
      "Train Epoch: 5 [58000/60000 (1e+02%)]\t1.532317\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9668/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0e+00%)]\t1.540482\n",
      "Train Epoch: 6 [2000/60000 (3e+00%)]\t1.534787\n",
      "Train Epoch: 6 [4000/60000 (7e+00%)]\t1.540862\n",
      "Train Epoch: 6 [6000/60000 (1e+01%)]\t1.532018\n",
      "Train Epoch: 6 [8000/60000 (1e+01%)]\t1.577319\n",
      "Train Epoch: 6 [10000/60000 (2e+01%)]\t1.491443\n",
      "Train Epoch: 6 [12000/60000 (2e+01%)]\t1.574823\n",
      "Train Epoch: 6 [14000/60000 (2e+01%)]\t1.509343\n",
      "Train Epoch: 6 [16000/60000 (3e+01%)]\t1.530080\n",
      "Train Epoch: 6 [18000/60000 (3e+01%)]\t1.517601\n",
      "Train Epoch: 6 [20000/60000 (3e+01%)]\t1.547852\n",
      "Train Epoch: 6 [22000/60000 (4e+01%)]\t1.537217\n",
      "Train Epoch: 6 [24000/60000 (4e+01%)]\t1.524883\n",
      "Train Epoch: 6 [26000/60000 (4e+01%)]\t1.518486\n",
      "Train Epoch: 6 [28000/60000 (5e+01%)]\t1.509288\n",
      "Train Epoch: 6 [30000/60000 (5e+01%)]\t1.501952\n",
      "Train Epoch: 6 [32000/60000 (5e+01%)]\t1.551058\n",
      "Train Epoch: 6 [34000/60000 (6e+01%)]\t1.538796\n",
      "Train Epoch: 6 [36000/60000 (6e+01%)]\t1.548110\n",
      "Train Epoch: 6 [38000/60000 (6e+01%)]\t1.517038\n",
      "Train Epoch: 6 [40000/60000 (7e+01%)]\t1.513441\n",
      "Train Epoch: 6 [42000/60000 (7e+01%)]\t1.588109\n",
      "Train Epoch: 6 [44000/60000 (7e+01%)]\t1.534833\n",
      "Train Epoch: 6 [46000/60000 (8e+01%)]\t1.535203\n",
      "Train Epoch: 6 [48000/60000 (8e+01%)]\t1.513494\n",
      "Train Epoch: 6 [50000/60000 (8e+01%)]\t1.561739\n",
      "Train Epoch: 6 [52000/60000 (9e+01%)]\t1.543391\n",
      "Train Epoch: 6 [54000/60000 (9e+01%)]\t1.529023\n",
      "Train Epoch: 6 [56000/60000 (9e+01%)]\t1.551781\n",
      "Train Epoch: 6 [58000/60000 (1e+02%)]\t1.551629\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9703/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0e+00%)]\t1.537078\n",
      "Train Epoch: 7 [2000/60000 (3e+00%)]\t1.516309\n",
      "Train Epoch: 7 [4000/60000 (7e+00%)]\t1.513351\n",
      "Train Epoch: 7 [6000/60000 (1e+01%)]\t1.519757\n",
      "Train Epoch: 7 [8000/60000 (1e+01%)]\t1.505342\n",
      "Train Epoch: 7 [10000/60000 (2e+01%)]\t1.508454\n",
      "Train Epoch: 7 [12000/60000 (2e+01%)]\t1.538691\n",
      "Train Epoch: 7 [14000/60000 (2e+01%)]\t1.512294\n",
      "Train Epoch: 7 [16000/60000 (3e+01%)]\t1.534806\n",
      "Train Epoch: 7 [18000/60000 (3e+01%)]\t1.531224\n",
      "Train Epoch: 7 [20000/60000 (3e+01%)]\t1.516982\n",
      "Train Epoch: 7 [22000/60000 (4e+01%)]\t1.569677\n",
      "Train Epoch: 7 [24000/60000 (4e+01%)]\t1.540011\n",
      "Train Epoch: 7 [26000/60000 (4e+01%)]\t1.525524\n",
      "Train Epoch: 7 [28000/60000 (5e+01%)]\t1.529147\n",
      "Train Epoch: 7 [30000/60000 (5e+01%)]\t1.526072\n",
      "Train Epoch: 7 [32000/60000 (5e+01%)]\t1.524746\n",
      "Train Epoch: 7 [34000/60000 (6e+01%)]\t1.503992\n",
      "Train Epoch: 7 [36000/60000 (6e+01%)]\t1.519515\n",
      "Train Epoch: 7 [38000/60000 (6e+01%)]\t1.565795\n",
      "Train Epoch: 7 [40000/60000 (7e+01%)]\t1.525742\n",
      "Train Epoch: 7 [42000/60000 (7e+01%)]\t1.505138\n",
      "Train Epoch: 7 [44000/60000 (7e+01%)]\t1.523569\n",
      "Train Epoch: 7 [46000/60000 (8e+01%)]\t1.526968\n",
      "Train Epoch: 7 [48000/60000 (8e+01%)]\t1.526653\n",
      "Train Epoch: 7 [50000/60000 (8e+01%)]\t1.512858\n",
      "Train Epoch: 7 [52000/60000 (9e+01%)]\t1.527993\n",
      "Train Epoch: 7 [54000/60000 (9e+01%)]\t1.525217\n",
      "Train Epoch: 7 [56000/60000 (9e+01%)]\t1.541350\n",
      "Train Epoch: 7 [58000/60000 (1e+02%)]\t1.525809\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9698/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0e+00%)]\t1.505876\n",
      "Train Epoch: 8 [2000/60000 (3e+00%)]\t1.543271\n",
      "Train Epoch: 8 [4000/60000 (7e+00%)]\t1.530500\n",
      "Train Epoch: 8 [6000/60000 (1e+01%)]\t1.539983\n",
      "Train Epoch: 8 [8000/60000 (1e+01%)]\t1.554469\n",
      "Train Epoch: 8 [10000/60000 (2e+01%)]\t1.518792\n",
      "Train Epoch: 8 [12000/60000 (2e+01%)]\t1.600922\n",
      "Train Epoch: 8 [14000/60000 (2e+01%)]\t1.554531\n",
      "Train Epoch: 8 [16000/60000 (3e+01%)]\t1.515051\n",
      "Train Epoch: 8 [18000/60000 (3e+01%)]\t1.525792\n",
      "Train Epoch: 8 [20000/60000 (3e+01%)]\t1.563592\n",
      "Train Epoch: 8 [22000/60000 (4e+01%)]\t1.526518\n",
      "Train Epoch: 8 [24000/60000 (4e+01%)]\t1.512456\n",
      "Train Epoch: 8 [26000/60000 (4e+01%)]\t1.570420\n",
      "Train Epoch: 8 [28000/60000 (5e+01%)]\t1.540184\n",
      "Train Epoch: 8 [30000/60000 (5e+01%)]\t1.548748\n",
      "Train Epoch: 8 [32000/60000 (5e+01%)]\t1.512371\n",
      "Train Epoch: 8 [34000/60000 (6e+01%)]\t1.578036\n",
      "Train Epoch: 8 [36000/60000 (6e+01%)]\t1.573888\n",
      "Train Epoch: 8 [38000/60000 (6e+01%)]\t1.562436\n",
      "Train Epoch: 8 [40000/60000 (7e+01%)]\t1.521457\n",
      "Train Epoch: 8 [42000/60000 (7e+01%)]\t1.540678\n",
      "Train Epoch: 8 [44000/60000 (7e+01%)]\t1.561373\n",
      "Train Epoch: 8 [46000/60000 (8e+01%)]\t1.529185\n",
      "Train Epoch: 8 [48000/60000 (8e+01%)]\t1.536100\n",
      "Train Epoch: 8 [50000/60000 (8e+01%)]\t1.499019\n",
      "Train Epoch: 8 [52000/60000 (9e+01%)]\t1.550750\n",
      "Train Epoch: 8 [54000/60000 (9e+01%)]\t1.582555\n",
      "Train Epoch: 8 [56000/60000 (9e+01%)]\t1.532068\n",
      "Train Epoch: 8 [58000/60000 (1e+02%)]\t1.511105\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9721/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0e+00%)]\t1.498492\n",
      "Train Epoch: 9 [2000/60000 (3e+00%)]\t1.523762\n",
      "Train Epoch: 9 [4000/60000 (7e+00%)]\t1.548680\n",
      "Train Epoch: 9 [6000/60000 (1e+01%)]\t1.539134\n",
      "Train Epoch: 9 [8000/60000 (1e+01%)]\t1.525583\n",
      "Train Epoch: 9 [10000/60000 (2e+01%)]\t1.549073\n",
      "Train Epoch: 9 [12000/60000 (2e+01%)]\t1.520959\n",
      "Train Epoch: 9 [14000/60000 (2e+01%)]\t1.520286\n",
      "Train Epoch: 9 [16000/60000 (3e+01%)]\t1.541147\n",
      "Train Epoch: 9 [18000/60000 (3e+01%)]\t1.549592\n",
      "Train Epoch: 9 [20000/60000 (3e+01%)]\t1.551599\n",
      "Train Epoch: 9 [22000/60000 (4e+01%)]\t1.563192\n",
      "Train Epoch: 9 [24000/60000 (4e+01%)]\t1.535316\n",
      "Train Epoch: 9 [26000/60000 (4e+01%)]\t1.515706\n",
      "Train Epoch: 9 [28000/60000 (5e+01%)]\t1.510622\n",
      "Train Epoch: 9 [30000/60000 (5e+01%)]\t1.554197\n",
      "Train Epoch: 9 [32000/60000 (5e+01%)]\t1.533487\n",
      "Train Epoch: 9 [34000/60000 (6e+01%)]\t1.500509\n",
      "Train Epoch: 9 [36000/60000 (6e+01%)]\t1.525988\n",
      "Train Epoch: 9 [38000/60000 (6e+01%)]\t1.524712\n",
      "Train Epoch: 9 [40000/60000 (7e+01%)]\t1.557226\n",
      "Train Epoch: 9 [42000/60000 (7e+01%)]\t1.528458\n",
      "Train Epoch: 9 [44000/60000 (7e+01%)]\t1.506935\n",
      "Train Epoch: 9 [46000/60000 (8e+01%)]\t1.506306\n",
      "Train Epoch: 9 [48000/60000 (8e+01%)]\t1.516587\n",
      "Train Epoch: 9 [50000/60000 (8e+01%)]\t1.559304\n",
      "Train Epoch: 9 [52000/60000 (9e+01%)]\t1.530938\n",
      "Train Epoch: 9 [54000/60000 (9e+01%)]\t1.498857\n",
      "Train Epoch: 9 [56000/60000 (9e+01%)]\t1.532945\n",
      "Train Epoch: 9 [58000/60000 (1e+02%)]\t1.535504\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9723/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0e+00%)]\t1.503590\n",
      "Train Epoch: 10 [2000/60000 (3e+00%)]\t1.495755\n",
      "Train Epoch: 10 [4000/60000 (7e+00%)]\t1.498645\n",
      "Train Epoch: 10 [6000/60000 (1e+01%)]\t1.556173\n",
      "Train Epoch: 10 [8000/60000 (1e+01%)]\t1.494207\n",
      "Train Epoch: 10 [10000/60000 (2e+01%)]\t1.489840\n",
      "Train Epoch: 10 [12000/60000 (2e+01%)]\t1.501546\n",
      "Train Epoch: 10 [14000/60000 (2e+01%)]\t1.521564\n",
      "Train Epoch: 10 [16000/60000 (3e+01%)]\t1.516316\n",
      "Train Epoch: 10 [18000/60000 (3e+01%)]\t1.575651\n",
      "Train Epoch: 10 [20000/60000 (3e+01%)]\t1.543785\n",
      "Train Epoch: 10 [22000/60000 (4e+01%)]\t1.547618\n",
      "Train Epoch: 10 [24000/60000 (4e+01%)]\t1.527182\n",
      "Train Epoch: 10 [26000/60000 (4e+01%)]\t1.517464\n",
      "Train Epoch: 10 [28000/60000 (5e+01%)]\t1.505328\n",
      "Train Epoch: 10 [30000/60000 (5e+01%)]\t1.556029\n",
      "Train Epoch: 10 [32000/60000 (5e+01%)]\t1.502027\n",
      "Train Epoch: 10 [34000/60000 (6e+01%)]\t1.493146\n",
      "Train Epoch: 10 [36000/60000 (6e+01%)]\t1.486094\n",
      "Train Epoch: 10 [38000/60000 (6e+01%)]\t1.551744\n",
      "Train Epoch: 10 [40000/60000 (7e+01%)]\t1.540055\n",
      "Train Epoch: 10 [42000/60000 (7e+01%)]\t1.512689\n",
      "Train Epoch: 10 [44000/60000 (7e+01%)]\t1.532758\n",
      "Train Epoch: 10 [46000/60000 (8e+01%)]\t1.521440\n",
      "Train Epoch: 10 [48000/60000 (8e+01%)]\t1.535253\n",
      "Train Epoch: 10 [50000/60000 (8e+01%)]\t1.527324\n",
      "Train Epoch: 10 [52000/60000 (9e+01%)]\t1.544929\n",
      "Train Epoch: 10 [54000/60000 (9e+01%)]\t1.538212\n",
      "Train Epoch: 10 [56000/60000 (9e+01%)]\t1.552587\n",
      "Train Epoch: 10 [58000/60000 (1e+02%)]\t1.508795\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 9747/10000 (97%)\n",
      "\n",
      "Total time: 93.04 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()\n",
    "end_time = time.time()\n",
    "print(f'Total time: {end_time - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "/var/folders/lp/h9ryjfsj4wx5rsdk3mrqk3nh0000gn/T/ipykernel_17255/2541791753.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[0]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
