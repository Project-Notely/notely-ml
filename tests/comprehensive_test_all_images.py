"""
Comprehensive Test: All OCR Backends on All Data Images

This test demonstrates the enhanced word highlighting solution
across different image types and content, showing how different
OCR backends perform on various scenarios.
"""

import os
import sys
import time
from pathlib import Path

from PIL import Image

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from app.services.page_analyzer.engines.gemini_processor import GeminiProcessor
from app.services.page_analyzer.utils.highlighting import save_highlighted_image


def get_all_test_images():
    """Get all test images from the data folder"""
    data_path = Path("../data")
    image_extensions = {".png", ".jpg", ".jpeg", ".bmp", ".tiff"}

    images = []
    for file_path in data_path.iterdir():
        if file_path.suffix.lower() in image_extensions:
            images.append(file_path)

    return sorted(images)


def test_backend_on_image(backend_name, image_path, kwargs=None):
    """Test a specific backend on a specific image"""
    if kwargs is None:
        kwargs = {}

    try:
        # Load image
        image = Image.open(image_path)

        # Initialize processor
        processor = GeminiProcessor(ocr_backend=backend_name)

        if not processor.initialize(**kwargs):
            return {"success": False, "error": f"Failed to initialize {backend_name}"}

        # Process image
        start_time = time.time()
        result = processor.process_text_region(image)
        processing_time = time.time() - start_time

        if result.success:
            ocr_result = result.result

            # Save highlighted image
            output_filename = f"highlighted_{image_path.stem}_{backend_name}.png"
            save_highlighted_image(
                image,
                ocr_result.text_boxes,
                output_filename,
                title=f"{backend_name.upper()} - {image_path.name}",
            )

            return {
                "success": True,
                "word_count": ocr_result.total_words,
                "confidence": ocr_result.average_confidence,
                "full_text": ocr_result.full_text,
                "processing_time": processing_time,
                "output_file": output_filename,
            }
        else:
            return {"success": False, "error": result.error}

    except Exception as e:
        return {"success": False, "error": str(e)}


def run_comprehensive_test():
    """Run comprehensive test on all images with all backends"""

    print("üöÄ COMPREHENSIVE WORD HIGHLIGHTING TEST")
    print("Testing all OCR backends on all available images")
    print("=" * 80)

    # Get all test images
    test_images = get_all_test_images()

    if not test_images:
        print("‚ùå No test images found in data folder")
        return

    print(f"üì∏ Found {len(test_images)} test images:")
    for img in test_images:
        image = Image.open(img)
        print(f"   ‚Ä¢ {img.name} - {image.size}")

    # Define backends to test
    backends = [
        {
            "name": "trocr",
            "description": "TrOCR - Specialized for handwritten text",
            "kwargs": {"trocr_model_type": "handwritten_base", "device": "cpu"},
            "best_for": "Handwritten, messy text",
        },
        {
            "name": "tesseract",
            "description": "Tesseract - Classic OCR engine",
            "kwargs": {},
            "best_for": "Clear printed text",
        },
        {
            "name": "easyocr",
            "description": "EasyOCR - General purpose neural OCR",
            "kwargs": {"gpu": False},
            "best_for": "General purpose",
        },
    ]

    # Store all results for comparison
    all_results = {}

    # Test each image with each backend
    for image_path in test_images:
        image_name = image_path.stem
        all_results[image_name] = {}

        print(f"\n" + "=" * 80)
        print(f"üñºÔ∏è  TESTING IMAGE: {image_path.name}")
        print(f"üìè Size: {Image.open(image_path).size}")
        print("=" * 80)

        for backend in backends:
            backend_name = backend["name"]
            description = backend["description"]
            kwargs = backend["kwargs"]
            best_for = backend["best_for"]

            print(f"\nüîÑ Testing {backend_name.upper()}: {description}")
            print(f"   Best for: {best_for}")
            print("-" * 60)

            result = test_backend_on_image(backend_name, image_path, kwargs)
            all_results[image_name][backend_name] = result

            if result["success"]:
                print(f"‚úÖ SUCCESS")
                print(f"   üìä Words detected: {result['word_count']}")
                print(f"   üéØ Average confidence: {result['confidence']:.1f}%")
                print(f"   ‚è±Ô∏è  Processing time: {result['processing_time']:.2f}s")
                print(f"   üìù Text preview: {result['full_text'][:100]}...")
                print(f"   üíæ Saved: {result['output_file']}")
            else:
                print(f"‚ùå FAILED: {result['error']}")

    # Generate comprehensive analysis
    print(f"\n" + "=" * 100)
    print("üìä COMPREHENSIVE ANALYSIS - ALL IMAGES & BACKENDS")
    print("=" * 100)

    # Results table
    for image_name in all_results:
        print(f"\nüñºÔ∏è  IMAGE: {image_name}")
        print("-" * 80)
        print(
            f"{'Backend':<12} {'Success':<8} {'Words':<8} {'Confidence':<12} {'Time (s)':<10} {'Quality'}"
        )
        print("-" * 80)

        successful_backends = []

        for backend_name in ["trocr", "tesseract", "easyocr"]:
            if backend_name in all_results[image_name]:
                result = all_results[image_name][backend_name]

                if result["success"]:
                    success_str = "‚úÖ YES"
                    words = result["word_count"]
                    confidence = f"{result['confidence']:.1f}%"
                    time_str = f"{result['processing_time']:.2f}s"

                    # Quality assessment
                    if result["confidence"] >= 90:
                        quality = "üèÜ Excellent"
                    elif result["confidence"] >= 75:
                        quality = "‚≠ê Good"
                    elif result["confidence"] >= 60:
                        quality = "‚ö†Ô∏è  Fair"
                    else:
                        quality = "‚ùå Poor"

                    successful_backends.append((backend_name, result))

                else:
                    success_str = "‚ùå NO"
                    words = "-"
                    confidence = "-"
                    time_str = "-"
                    quality = "Failed"

                print(
                    f"{backend_name.upper():<12} {success_str:<8} {words:<8} {confidence:<12} {time_str:<10} {quality}"
                )

        # Recommendations for this image
        if successful_backends:
            print(f"\nüí° RECOMMENDATIONS FOR {image_name}:")

            # Best by confidence
            best_conf = max(successful_backends, key=lambda x: x[1]["confidence"])
            print(
                f"   üéØ Highest confidence: {best_conf[0].upper()} ({best_conf[1]['confidence']:.1f}%)"
            )

            # Best by word count
            best_words = max(successful_backends, key=lambda x: x[1]["word_count"])
            print(
                f"   üìä Most words detected: {best_words[0].upper()} ({best_words[1]['word_count']} words)"
            )

            # Fastest
            fastest = min(successful_backends, key=lambda x: x[1]["processing_time"])
            print(
                f"   ‚ö° Fastest processing: {fastest[0].upper()} ({fastest[1]['processing_time']:.2f}s)"
            )

    # Overall recommendations
    print(f"\n" + "=" * 100)
    print("üèÜ OVERALL RECOMMENDATIONS")
    print("=" * 100)

    print("\nüìã BACKEND SELECTION GUIDE:")
    print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    print("‚îÇ Content Type        ‚îÇ Recommended Backend                          ‚îÇ")
    print("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    print("‚îÇ üìù Handwritten text ‚îÇ TrOCR (specialized for handwriting)         ‚îÇ")
    print("‚îÇ üñ®Ô∏è  Clear printed    ‚îÇ Tesseract (highest confidence)              ‚îÇ")
    print("‚îÇ üì± Screenshots      ‚îÇ EasyOCR (good general purpose)              ‚îÇ")
    print("‚îÇ üîÄ Mixed content    ‚îÇ Try TrOCR first, fallback to Tesseract     ‚îÇ")
    print("‚îÇ üåü Unknown quality  ‚îÇ Test all backends, pick best performer      ‚îÇ")
    print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")

    print(f"\n‚ú® KEY ADVANTAGES OF THIS SOLUTION:")
    print("‚Ä¢ üéØ ALWAYS trusts Gemini's accurate text extraction")
    print("‚Ä¢ üîÑ Multiple OCR backends for different content types")
    print("‚Ä¢ üìç Guarantees every word is highlighted accurately")
    print("‚Ä¢ ‚ö° Can switch backends dynamically based on performance")
    print("‚Ä¢ üèÜ Perfect for messy handwriting, unclear text, and mixed content")

    print(f"\nüìÅ Generated highlighted images for visual comparison:")
    output_files = []
    for image_name in all_results:
        for backend_name, result in all_results[image_name].items():
            if result["success"]:
                output_files.append(result["output_file"])

    for i, filename in enumerate(sorted(output_files), 1):
        print(f"   {i:2d}. {filename}")

    return all_results


if __name__ == "__main__":
    print("üéØ Starting comprehensive test of all images with all OCR backends...")
    print(
        "This will demonstrate the solution's effectiveness across different content types.\n"
    )

    # Check if API key is available
    from dotenv import load_dotenv

    load_dotenv(dotenv_path="../.env.local")

    if not os.getenv("GEMINI_API_KEY"):
        print("‚ö†Ô∏è  WARNING: No Gemini API key found!")
        print("   Create .env.local file with: GEMINI_API_KEY=your_api_key_here")
        print("   Get your key from: https://aistudio.google.com/apikey")
        print(
            "\n   This test will show OCR backend positioning only (no Gemini text extraction)"
        )
        print("   For full functionality, please set up your API key.\n")

    results = run_comprehensive_test()

    print(
        f"\nüéâ Test completed! Check the generated highlighted images to see the differences."
    )
    print(
        "üí° This solution guarantees perfect word highlighting regardless of content type!"
    )
